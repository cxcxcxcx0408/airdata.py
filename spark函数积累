#alias(alias)
使用新名称并返回此列

#withColumn
Returns a new DataFrame by adding a column or replacing the existing column that has the same name.

#Binarizer 将数据二值化
Binarize a column of continuous features given a threshold. 
Since 3.0.0, Binarize can map multiple columns at once by setting the inputCols parameter. 
Note that when both the inputCol and inputCols parameters are set, an Exception will be thrown. The threshold parameter is used for single column usage, and thresholds is for multiple columns.
#处理多值
df2 = spark.createDataFrame([(0.5, 0.3)], ["values1", "values2"])
binarizer2 = Binarizer(thresholds=[0.0, 1.0])
binarizer2.setInputCols(["values1", "values2"]).setOutputCols(["output1", "output2"])

#pyspark matrix with dummy variables
https://stackoverflow.com/questions/35879372/pyspark-matrix-with-dummy-variables

#正则表达式
Spark利用了Java正则表达式的全部功能。其中两个关键功能：regexp_extract和regexp_repalce，这两个函数分别提取值和替换值。
例子见：https://snaildove.github.io/2019/08/05/Chapter6_Working-with-Different-Types-of-Data(SparkTheDefinitiveGuide)_online/

如果想用其他字符替换给定的字符，Spark还提供了translation函数来替换这些值。但这是在字符级别完成的。
